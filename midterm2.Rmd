---
title: "Sta 523 - Midterm 2 - Spring 2016"
output: rmarkdown::html_document
runtime: shiny
---

<br/><br/>

### Rules

1. Your solutions must be written up using this R Markdown (Rmd) file, this file must include your code and write up for each task.

2. This exam is open book, open internet, closed other people. You may use *any* online or book based resource you would like, but you must include citations for any code that you use (directly or indirectly). You *may not* consult with anyone else about this exam other than the Professor or TAs for this course - this includes posting anything online.

3. You have until 11:59 pm on Monday, December 5th to complete this exam and turn it in via your personal Github repo - late work will not be accepted. Technical difficulties are not an excuse for late work - do not wait until the last minute to commit / push.

4. All of your answers must include a brief description / writeup of your approach. This includes both annotating / commenting your code *and* a separate written descriptions of all code / implementations. I should be able to suppress *all* code output in your document and still be able to read and make sense of your answers.

5. You may use any packages you want other than the `darksky` package.

6. The most important goal is to write code that can accomplish the given tasks, note however that grading will be partially based on the quality of the code you write - elegant, efficient code will be rewarded and messy, slow code will be penalized.

<br/>
<br/><br/>


### Shiny Weather

Dark Sky is an iOS and a website that provides "hyperlocal" weather forecasts. They make their data available to third parties via a web API which we will be using to create a simple shiny app. 

In order to access this API you need an account - if you go to https://darksky.net/dev/ you can sign up for an API account. Once you have registered you will have access to a usage console that includes a unique secret key (the long alphanumeric string at the bottom of the page) you will use to access the API. You can make up to 1000 API requests per day without incurring any cost, so there is no need to enter any billing information.

Documentation for the Dark Sky API can be found [here](https://darksky.net/dev/docs) and includes all information about how to create a properly formated API request and the details of the JSON format of the returned data.


#### Task 1 - Getting data from Dark Sky (30 pts)

Your first task is to write a single function that accepts an API key, latitude, longitude, and optionally a date and returns a data frame containing the hourly forecast for the given location (and time). The Dark Sky forecast API provides a number of different weather related predictions - all of these quantities should be returned by your function along with a properly formated datetime column. You do not need to return any of the currently, minutely, daily or other data. Note that you can exclude some of these results via your API request.

Some additional requirements:

* If no date is provided the results should be the hourly forecast for the next two days, this is the default behavior of a [Forecast Request](https://darksky.net/dev/docs/forecast).

* If a date is provided then hourly forecast data for the two days *prior* and two days *following* that date should be returned - this can be achieved via a [Time Machine Request](https://darksky.net/dev/docs/time-machine). 


<hr/>

<!-- Include your write up here and or below -->
I start this tasks of writing get_darksky function by two steps. First, if the date input is NULL, which means no date provided in this call, I will achieve the url from Forecast Request. Second, I obtain the urls from Time Machine Request if the date is specified. Since Time Machine Request will only provide the data for one particular day, in order to obtain two days prior and two days following, this step will be accomplished by a loop iteration from the starting day(two days before), which is the input date minus three, to the ending day(two days after). I will save the url(s) into the variable called url. After retrieving the url, the following step will be achieved by a loop iterating over the url. At the first time of iteration, beginning by obtaining the JSON file (JSON-formatted object is the result from API responding) from that url, I only include the date from hourly results and save it as a data frame. Besides, I also change the time variable into standardized date format, which makes the table more human readable. Finally I save the result data frame `hourlydate` into the final `data`. When the iteration times increases, the same approach will be applied, with the only difference that every time the result data frame `hourlydate` will be fully merged with `data`. This ensures our `data` contains all the data we needed from the looping. Finally, the `data` will be returned in this function. 


```{r}
# load library
library(rvest)
library(dplyr)
library(stringr)
#library(rjson)
library(jsonlite)
library(Rcpp)
library(anytime)
library(ggplot2)
library(shiny)
library(ggmap)
library(reshape2)
library(scales)
library(lubridate)
```


```{r}
 date = "2016-11-03"
 key = "3fb318b0ba046bde99d853585774584e"

# get_darksky functions
get_darksky = function(key, lat, long, date = NULL){

  #retrive url according to whether the date is input or not 
  if(is.null(date)){
    # retrive url when date is null 
    url =paste0("https://api.darksky.net/forecast/",key,"/" ,lat,",",long)
  }
  # retrive url when date is not null 
  else{
    url = NULL
    # modify date into standard format
    date = paste(date, "12:00:00 EDT")
    # starting date from two days before
    date = paste(date(date) -3, "12:00:00 EDT")
    # loop the date from the starting date to continuous five days(the two days following the input date)
    for (i in 1:4){
      newdate = paste(date(date) + i, "12:00:00 EDT")
      # retrive the url for each of the date
      url1 = paste0("https://api.darksky.net/forecast/",key,"/",lat,",",long,",",as.numeric(as.POSIXlt(newdate)))
      # save all urls to url
      url = c(url,url1)
    }
  }
  # for (i in 1:4){
  #     newdate = paste(date(date) + i, "12:00:00 EDT")
  #     print(newdate)
  # }
# j1 = fromJSON(url[1])
# h1 = as.data.frame(j1$hourly$data)
# h1$time = anytime(as.numeric(h1$time))
# j2 = fromJSON(url[2])
# h2 = as.data.frame(j2$hourly$data)
# h2$time = anytime(as.numeric(h2$time))
# j3 = fromJSON(url[3])
# h3 = as.data.frame(j3$hourly$data)
# h3$time = anytime(as.numeric(h3$time))
# j4 = fromJSON(url[4])
# h4 = as.data.frame(j4$hourly$data)
# h4$time = anytime(as.numeric(h4$time))
# m1 = merge(h1,h4, all = TRUE)

  #loop over all urls to create a dataframe that including hourly data  
  for(i in seq_along(url)){
    # loop at the first url 
    if(i == 1){
    # retrive JSON fill from the url 
    json = fromJSON(url[i])
    # save the hourly data as dataframe
    hourlydate = as.data.frame(json$hourly$data)
    # formate the time to standard date format 
    hourlydate$time = anytime(as.numeric(hourlydate$time))
    # save hourlydate to data 
    data = hourlydate
    }
    # loop over the following urls
    else{
    # retrive JSON fill from the url 
    json = fromJSON(url[i])
    # save the hourly data as dataframe
    hourlydate = as.data.frame(json$hourly$data)
    # formate the time to standard date format 
    hourlydate$time = anytime(as.numeric(hourlydate$time))
    # merge the hourlydate with previous saved data file into data
    data = merge(data, hourlydate,all = TRUE)
    }
  }
  # return data which contains all hourly forecast data regarding to the request
return(data)
}
```


<br/>



#### Task 2 - Prediction Locations (30 pts)

Your second task is to scrap US city location information from the following Wikipedia page: https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population. The entire table should be read into R via web scraping (think `rvest`).

Your final data frame should meet the following requirements

* Rows should be filtered to only contains cities with more than 500,000 residents during the 2010 Census

* City and state names should be cleaned up 

* Location should be split up into new numeric latitude and longitude columns. Note that western longitudes and southern latitudes should be negative.


<hr/>

<!-- Include your write up here and or below -->
I accomplish this task by first retrieving the table from Wikipedia page. This step is completing by scarping html page via html nodes. By obtaining the table, I need to transform all numerical results to numeric values and get rid of all special characters for all numerical variables. For State and City variable, I need to clean them up by dropping all unnecessary values. These steps will be achieved by string extraction, string replacement, etc. Then I would create two new columns named latitude and longitude. By extracting latitude and longitude values from Location variable via string extraction, I save all valued into these two columns respectively. The final table will contains all numerical values in numeric format and cleaned City and State as well as Location. Finally, by dropping Location and filter out with `2010 Census` greater than 500000, we retrieve our final table named as us_locs. 

```{r}
# retrive page from the Wikipedia url 
page = read_html(paste0("https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population"))
# retrive table from page
table = page %>%
  # speficy the table nodes
  html_nodes(xpath = '//*[@id="mw-content-text"]/table[4]') %>%
  # retrive table 
  html_table()
# assign table with the first elment of the table list 
table = table[[1]]

### change all numbers into numeric values through stringr
# get rid of the special characters in Change and transform it to numeric values
table$Change=str_extract(table$Change,"(\\+|\\âˆ’)\\d+\\.\\d+")
table$Change=as.numeric(str_replace_all(table$Change,"âˆ’","-"))/100
# clean up variable of City by droppinng numbers following some of the city names 
table$City = str_replace(table$City, "\\[\\d+\\]", "")
# only extract the sq mi values for `2014 land area` and transform into numeric values 
table$`2014 land area` = as.numeric(str_extract(table$`2014 land area`, "\\d+\\.\\d+"))
# only extract the per sq mi values for `2010 population density` and transform into numeric values 
table$`2010 population density` = str_replace(table$`2010 population density`, "\\d+\\â™ ", "")
table$`2010 population density` = str_replace_all(table$`2010 population density`, ",", "")
table$`2010 population density` = as.numeric(str_extract(table$`2010 population density`, "\\d+"))
# create a new column called latitude and save numeric transformed latitude to it 
table$latitude = as.numeric(str_extract(table$Location, "\\d+\\.\\d+"))
# create a new column called longitude and save numeric transformed longitude to it 
table$longitude = as.numeric(str_extract(table$Location, "\\-\\d+\\.\\d+"))
# dropping "," in `2010 Census` and transform to numeric values 
table$`2010 Census` = as.numeric(str_replace_all(table$`2010 Census`, ",", ""))
# dropping "," in `2015 estimate` and transform to numeric values 
table$`2015 estimate` = as.numeric(str_replace_all(table$`2015 estimate`, ",", ""))

# revise column names
names(table)[3] = paste("State")
names(table)[7] = paste("2014 land area(sq mi)")
names(table)[8] = paste("2010 population density(per sq mi)")

# Create your location data frame here
# save the data from into us_locs
us_locs = table %>% 
  # dropping variable location 
  select(-Location) %>%
  # filter out with `2010 Census` graeter than 500000
  filter(`2010 Census` > 500000)
```


<br/>
 
#### Task 3 - Shiny Predictions (40 pts)

Your third task is to create a shiny app to provide a GUI interface for the `get_darksky` function we wrote earlier.
This app should allow the user to select a city from a list and provide a visualization of the hourly weather forecast for that location. 

Your app should have the following features:

* Your visualization should always include the temperature, but also allow the user to select a second quantity (e.g. precipitation chance, barometric pressure, etc.) to optionally display on the *same* plot - this must also include appropriate axes and legend.

* The list of cities should come from the data frame your created in Task 2.

* When a city is selected its latitude and longitude should also be reported in the user interface. 

* UI should also allow the user to specify a historical date for the forecast

* Extra credit for adding bells and whistles and overall polish / design of your app.


<hr/>

<!-- Include your write up here and or below -->

```{r echo=FALSE}
# Modify this default shiny app

shinyApp(
  # ui part 
  ui = fluidPage(
    # title for the app
     titlePanel("Hourly Weather Forecast"),
         # input selection for the city, options come from task2
         selectInput(inputId = "city", 
                      label = "Please choose the city",
                      choices = us_locs$City),
         hr(),
         # input selection for second quantity, options come from task1 with only the continuous variables 
         selectInput(inputId = "second",
                     label = "Please select second quantity",
                     choices = c("No Selection"),
                     selected = "No Selection"
                     ),
         hr(),
         h4("Historical Date"),
         checkboxInput(inputId = "check",
                        label = "check if you want historical weather",
                        value = FALSE
         ),
         hr(),
         # input selection of data time 
         conditionalPanel(condition = "input.check == true",
                          dateInput(inputId = "date",
                          label = "Please specify the date:",
                          format = "yyyy-mm-dd")
         ),
       #   dateInput(inputId = "date",
       #           label = "Please specify the date:",
       #           format = "yyyy-mm-dd"
       # ),
        hr(),
     # text input of key values, the default is the value of mine 
        textInput(inputId = "key", 
                  label = "key", 
                  value = "3fb318b0ba046bde99d853585774584e"),
        mainPanel(
          h4("results"),
          # condition panel used for check condition 
          conditionalPanel(
            # if the input value of second is "No selection", display the following plot
            condition = "input.second != 'No Selection'",
            plotOutput("distPlot")
          ),
            conditionalPanel(
            # if the input value of second is not "No selection", display the following plot
            condition = "input.second == 'No Selection'",
            plotOutput("plot1")
          ),
           # always display table1
           textOutput("text1"),
           tableOutput("table1")
        )
  ),
  # server part 
  server = function(input, output, session) 
  {   
    # key value reactive to the text input of key values 
    key = reactive({input$key})
    # obtain location reactive to the input city, using geocode transform to latitude and longitude 
    location = reactive({
      geocode(input$city)
    })
    # lat reactive to the second list of location 
    lat = reactive({location()[[2]]})
    # long reactive to the first list of location 
    long = reactive({location()[[1]]})
    # date reactvie to the input date value
    date = reactive({input$date})
    # retrive numerical results from result() and return the colnames
    features = reactive({
      df = result()[,sapply(result(), is.numeric)] %>%
        select(-temperature)
      return(colnames(df))
    })
    # update input selection of second regarding to previous selected column names 
    observe({
      updateSelectInput(session,
                        inputId = "second",
                        label = "Please select second quantity", 
                        choices = c("No Selection",paste(features())),
                        selected = "No Selection")
    })
    # result reactive to the get_darksky function taking key, lat, long and date as the input and returns a data frame result 
    result = reactive({
      # when the date is not current date or forcast is checked
      if(input$check == TRUE){
      get_darksky(key = key(),
                  lat = lat(),
                  long = long(),
                  date = date())
      }
      # else condition 
      else{
      get_darksky(key = key(),
                  lat = lat(),
                  long = long())
      }
    })
    
    # second reactive to the input of second selection 
    second = reactive({input$second})
      output$text1 = renderText({
        print(paste("The latitude and longitude in", input$city, ":"))
      })
    # output table as a data frame displaying the latitude and longitude respect to the input city 
    output$table1 = renderTable({
        aa1 = lat()
        bb1 = long()
        data.frame("latitude" = aa1, "longitude" = bb1)
     })
     # output plot when second is not no selection, the plot is the trend plot of temperature and the second selection regarding the input city 
     output$distPlot = renderPlot({
       # create the new melted data frame called mm combing temperature and the second selected quantity, which will used for ggplot
       mm = melt(result()[,c("time","temperature",second())], id.var="time")
       # ggplot the new data frame with repect to the same x axis and different y response
       ggplot(mm, aes(x = time, y = value)) +
         geom_line(aes(color = variable)) +
         # set ggplot title name
         ggtitle(paste("Temperature and" ,second(), "record in", input$city)) +
         # transform x axis into hourly time format
         scale_x_datetime(labels = date_format("%y/%m/%d :%H:%M"), breaks=pretty_breaks(n=45)) +
         labs(x="Hours") +
         # modify x axis text display
         theme(axis.text.x = element_text(angle=45,hjust=1)) +
         # generate the facet grid
         facet_grid(variable ~ ., scales = "free_y") +
         theme(legend.position = "none") +
         theme(plot.title = element_text(family = "Trebuchet MS", color="#666666", face="bold", size=24, hjust=0))
      })
    # output plot when second is  no selection, the plot is the trend plot of temperature regarding the input city
    output$plot1 = renderPlot({
      ggplot(result(), aes(x = time, y = result()$temperature)) +
        geom_line() +
        # set ggplot title name
        ggtitle(paste("Temperature record in", input$city)) +
        # transform x axis into hourly time format
        scale_x_datetime(labels = date_format("%y/%m/%d :%H:%M"), breaks=pretty_breaks(n=45)) +
        # modify x axis text display
        theme(axis.text.x = element_text(angle=45,hjust=1)) +
        # modify labs of x and y axis
        labs(x="Hours",y="Temperature") +
        # modify title font and size
        theme(plot.title = element_text(family = "Trebuchet MS", color="#666666", face="bold", size=24, hjust=0))
    })
  }
)
```